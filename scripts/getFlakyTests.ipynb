{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77f8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "import astor\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from analyzer import Analyzer\n",
    "from operator import itemgetter\n",
    "from functionObject import FunctionObject\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5b50353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main variables\n",
    "# folderPath = sys.argv[1]\n",
    "folderPath ='../data/repos_'\n",
    "projectName = folderPath.split(\"/\")[-1]\n",
    "\n",
    "def main():\n",
    "#     checkUsage()\n",
    "\n",
    "    # Get all python files in the project folder\n",
    "    pythonFiles = findPythonFiles(folderPath)\n",
    "    functionsInProject = []\n",
    "\n",
    "    print(\"Project: \", projectName)\n",
    "    print(\"Number of Python files to analyze: \", len(pythonFiles), \"\\n\")\n",
    "\n",
    "    # For each file, build AST, get function and test objects\n",
    "    for i in tqdm(range(0, len(pythonFiles))):\n",
    "        pythonFilePath = pythonFiles[i]\n",
    "        pythonFile = getPath(pythonFilePath)\n",
    "\n",
    "        # Exceptions\n",
    "        if \"hue\" in projectName and \"/desktop/core/ext-py/\" in pythonFilePath:\n",
    "            continue\n",
    "        if \"jira\" in projectName and \".tox\" in pythonFilePath:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Create source code's AST\n",
    "            tree = astor.code_to_ast.parse_file(pythonFilePath)\n",
    "        except SyntaxError:\n",
    "            print(\"Syntax Error in file, skiping. \", pythonFilePath)\n",
    "            continue\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Decode Error in file, skiping. \", pythonFilePath)\n",
    "            continue\n",
    "        \n",
    "        # Help to find functions' class name\n",
    "        tree = setParents(tree)\n",
    "\n",
    "        # Browse the AST\n",
    "        analyzer = Analyzer()\n",
    "        analyzer.visit(tree)\n",
    "\n",
    "\n",
    "        # Set projectName and fileName for each function, add to list\n",
    "        for function in analyzer.objects:\n",
    "            function.setProjectName(projectName)\n",
    "            function.setFileName(pythonFile[1:])\n",
    "            fileName = function.getFileName().split(\"/\")[-1]\n",
    "            if fileName.startswith(\"test_\") or fileName.endswith(\"_test.py\"):\n",
    "                function.setIsTest(True)\n",
    "            functionsInProject.append(function)\n",
    "\n",
    "    countFunction, countTest, countFlaky, countNonFlaky = getGlobalStatistics(functionsInProject)\n",
    "\n",
    "    # Display statistics\n",
    "    print(\"\\nNumber of Functions: \", countFunction)\n",
    "    print(\"Number of Tests: \", countTest)\n",
    "    print(\"Number of Flaky Tests: \", countFlaky)\n",
    "    print(\"Number of Non Flaky Tests: \", countNonFlaky)\n",
    "\n",
    "    # To JSON\n",
    "    functionsInProject = [f.toJSON() for f in functionsInProject]\n",
    "    \n",
    "    \n",
    "    # # Save results to JSON file\n",
    "    for func in functionsInProject:\n",
    "        name=func.get('functionName')\n",
    "        saveResults(func, name)\n",
    "    \n",
    "#     print(functionsInProject)\n",
    "#     Add Most similar methods to each test\n",
    "#     dataset = addCut2Test(functionsInProject)\n",
    "#     print(\"Number of Flaky Tests with CUT added to dataset: \", len(dataset))\n",
    "\n",
    "    # Save results to JSON file\n",
    "#     saveResults(dataset, projectName)\n",
    "    \n",
    "def getGlobalStatistics(functionsInProject):\n",
    "    # Counter for statistics\n",
    "    countFlaky = 0\n",
    "    countNonFlaky = 0\n",
    "    countTest = 0\n",
    "    countFunction = 0\n",
    "\n",
    "    # Count numbers for the whole list\n",
    "    for obj in functionsInProject:\n",
    "        if obj.getIsTest():\n",
    "            countTest += 1\n",
    "            if obj.getIsMarkedFlaky():\n",
    "                countFlaky += 1\n",
    "                print(obj.getFunctionName(), obj.getClassName(), obj.getFileName())\n",
    "            else:\n",
    "                countNonFlaky += 1\n",
    "        else:\n",
    "            countFunction += 1\n",
    "\n",
    "    return countFunction, countTest, countFlaky, countNonFlaky\n",
    "\n",
    "def findPythonFiles(filepath):\n",
    "    \"\"\"Return a list of all .py files in the given filepath\"\"\"\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".py\"):\n",
    "                paths.append(os.path.join(root, file))\n",
    "    return paths\n",
    " \n",
    "def setParents(tree):\n",
    "    \"\"\"Add info about parent Node\"\"\"\n",
    "    for node in ast.walk(tree):\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            child.parent = node\n",
    "    return tree\n",
    "\n",
    "def getPath(pythonFilePath):\n",
    "    \"\"\"Get relative path (intra project)\"\"\"\n",
    "    pythonFile = pythonFilePath.replace(folderPath, '.')\n",
    "    return pythonFile\n",
    "\n",
    "def getTestAndCUT(test, functionsInProject, nb):\n",
    "    \"\"\"\n",
    "    Return a test with its most similar methods, supposed to be part of the CUT.\n",
    "    Parameters\n",
    "    ----------\n",
    "    test: A test object, {ClassName, MethodName, ProjectName, Body, Label:\"test\"}\n",
    "    allMethods: A list of method objects. {ClassName, MethodName, ProjectName, Body, Label:\"method\"}\n",
    "    nb: Number of similar methods to find\n",
    "    Returns\n",
    "    -------\n",
    "    test: A final test object, {ClassName, MethodName, ProjectName, Body, \"test\", cut_1, cut_2...}\n",
    "    \"\"\"\n",
    "\n",
    "    # Init allFunctions\n",
    "    allFunctions = []\n",
    "    for function in functionsInProject:\n",
    "        if function[\"isTest\"] == False:\n",
    "            allFunctions.append(function)\n",
    "\n",
    "    # Build Arrays of bodies\n",
    "    testBody = [ test[\"Body\"] ]\n",
    "    methodsBody = list(map(itemgetter('Body'), allFunctions))\n",
    "\n",
    "    # Vectorize\n",
    "\n",
    "    # To use if you want to deal with CamelCase:\n",
    "    # vectorizer = TfidfVectorizer(preprocessor=CustomPreProcessor)\n",
    "    \n",
    "    # TF-IDF Approach\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Fit to all Tests + Methods bodies vocabulary length\n",
    "    vectorizer.fit(testBody+methodsBody)\n",
    "    # Vectorize all Tests, and all Methods based on vector size established line before\n",
    "    X_Test = vectorizer.transform(testBody)\n",
    "    X_Methods = vectorizer.transform(methodsBody)\n",
    "    \n",
    "    # Similarity\n",
    "\n",
    "    # Computing similarities between selected test and all methods\n",
    "    cosine_similarities = linear_kernel(X_Test, X_Methods).flatten()\n",
    "    # Retrieving 5 most similar methods to selected test\n",
    "    similarMethodsIndex = cosine_similarities.argsort()[:-nb-1:-1]\n",
    "    # print(nb, \" most similar methods:\")\n",
    "    # print(similarMethodsIndex)\n",
    "\n",
    "    similarMethods = []\n",
    "    for i in similarMethodsIndex:\n",
    "        # Get whole method based on index of similar method, append to final array\n",
    "        similarMethods.append(allFunctions[i])\n",
    "\n",
    "    newTest = buildTestWithCUT(test, similarMethods)\n",
    "\n",
    "    return newTest\n",
    "\n",
    "def buildTestWithCUT(test, similarMethods):\n",
    "    \"\"\"\n",
    "    Add CUT to a test.\n",
    "    Parameters\n",
    "    ----------\n",
    "    test: The test to add the CUT\n",
    "    similarMethods: The CUT we want to add to the test\n",
    "    Returns\n",
    "    -------\n",
    "    test: The test with its CUT\n",
    "    \"\"\"\n",
    "    c = 1\n",
    "    for method in similarMethods:\n",
    "        keyName = \"CUT_\" + str(c)\n",
    "        test[keyName] = method[\"Body\"]\n",
    "        c += 1\n",
    "    return test\n",
    "\n",
    "def addCut2Test(functionsInProject):\n",
    "    print(\"\\nAdding CUT to tests...\")\n",
    "    dataset = []\n",
    "    # For each function in list\n",
    "    for function in tqdm(functionsInProject):\n",
    "        # If it is a test\n",
    "        if function[\"isTest\"] == True:\n",
    "            # We find its 5 most similar functions\n",
    "            test = function\n",
    "            test = getTestAndCUT(test, functionsInProject, 5)\n",
    "            dataset.append(test)\n",
    "    print(\"Done.\\n\")\n",
    "    return dataset\n",
    "\n",
    "def saveResults(dic, name):\n",
    "    \"\"\"Save results to file\"\"\"\n",
    "    fileName = \"../data/repos_/\" + name + \".json\"\n",
    "    \n",
    "    with open(fileName, 'w') as json_file:\n",
    "        json.dump(dic, json_file, indent=4) \n",
    "\n",
    "def checkUsage():\n",
    "    \"\"\"Check the programs' arguments\"\"\"\n",
    "    if len(sys.argv) != 2 or not os.path.isdir(sys.argv[1]):\n",
    "        print(\"Usage: python main.py [path/to/project]\")\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a2c552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 74.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project:  repos_\n",
      "Number of Python files to analyze:  3 \n",
      "\n",
      "Syntax Error in file, skiping.  ../data/repos_/Zebfred_&_DS-OOP-Review/Tests_&_datafunction_test.py\n",
      "\n",
      "Number of Functions:  0\n",
      "Number of Tests:  9\n",
      "Number of Flaky Tests:  0\n",
      "Number of Non Flaky Tests:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411be34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9188ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dfe3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
