{
    "functionName": "test_tokenizer",
    "className": null,
    "fileName": "/roniemartinez_&_DocCron/tests_&_test_parser.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "assert [['*'] * 6] == list(doccron.tokenize('* * * * *'))\nassert [['*'] * 6] == list(doccron.tokenize('* * * * * *'))\nassert [['*'] * 6] == list(doccron.tokenize('*  * * * *'))\nassert [['*'] * 6, ['*'] * 6] == list(doccron.tokenize('* * * * *%* * * * * *')\n    )\nassert [['*'] * 6, ['*'] * 6] == list(doccron.tokenize(\n    \"\"\"* * * * *\n* * * * * *\"\"\"))\nassert [['*'] * 6] * 2 == list(doccron.tokenize(\"\"\"* * * * *\n    * * * * *\"\"\"))\nassert [['0,15,30,45', '0,6,12,18', '1,15,31', '*', '1,2,3,4,5', '*']] == list(\n    doccron.tokenize('0,15,30,45 0,6,12,18 1,15,31 * 1,2,3,4,5 *'))\nassert [['*'] * 7] == list(doccron.tokenize('*  * * * *', quartz=True))\n"
}