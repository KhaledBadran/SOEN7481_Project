{
    "functionName": "rrelu",
    "className": null,
    "fileName": "/Lasagne_&_Lasagne/lasagne_&_layers_&_special.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "\"\"\"\n    Convenience function to apply randomized rectify to a given layer's output.\n    Will set the layer's nonlinearity to identity if there is one and will\n    apply the randomized rectifier instead.\n\n    Parameters\n    ----------\n    layer: a :class:`Layer` instance\n        The `Layer` instance to apply the randomized rectifier layer to;\n        note that it will be irreversibly modified as specified above\n\n    **kwargs\n        Any additional keyword arguments are passed to the\n        :class:`RandomizedRectifierLayer`\n\n    Examples\n    --------\n    Note that this function modifies an existing layer, like this:\n\n    >>> from lasagne.layers import InputLayer, DenseLayer, rrelu\n    >>> layer = InputLayer((32, 100))\n    >>> layer = DenseLayer(layer, num_units=200)\n    >>> layer = rrelu(layer)\n\n    In particular, :func:`rrelu` can *not* be passed as a nonlinearity.\n    \"\"\"\nnonlinearity = getattr(layer, 'nonlinearity', None)\nif nonlinearity is not None:\n    layer.nonlinearity = nonlinearities.identity\nreturn RandomizedRectifierLayer(layer, **kwargs)\n"
}