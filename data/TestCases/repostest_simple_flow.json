{
    "functionName": "test_simple_flow",
    "className": "TestSimple",
    "fileName": "/intel-analytics_&_Bigdl/pyspark_&_test_&_bigdl_&_test_simple_integration.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "FEATURES_DIM = 2\ndata_len = 100\nbatch_size = 32\nepoch_num = 5\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, FEATURES_DIM)\n    label = np.array((2 * features).sum() + 0.4)\n    return Sample.from_ndarray(features, label)\ntrainingData = self.sc.parallelize(range(0, data_len)).map(lambda i:\n    gen_rand_sample())\nmodel_test = Sequential()\nl1_test = Linear(FEATURES_DIM, 1).set_init_method(Xavier(), Zeros()).set_name(\n    'linear1_test')\nassert 'linear1_test' == l1_test.name()\nmodel_test.add(l1_test)\nmodel_test.add(Sigmoid())\nmodel = Sequential()\nl1 = Linear(FEATURES_DIM, 1).set_init_method(Xavier(), Zeros()).set_name(\n    'linear1')\nassert 'linear1' == l1.name()\nmodel.add(l1)\noptim_method = SGD(learningrate=0.01, learningrate_decay=0.0002,\n    weightdecay=0.0, momentum=0.0, dampening=0.0, nesterov=False,\n    leaningrate_schedule=Poly(0.5, int(data_len / batch_size * epoch_num)))\noptimizer = Optimizer.create(model=model_test, training_set=trainingData,\n    criterion=MSECriterion(), optim_method=optim_method, end_trigger=\n    MaxEpoch(epoch_num), batch_size=batch_size)\noptimizer.set_validation(batch_size=batch_size, val_rdd=trainingData,\n    trigger=EveryEpoch(), val_method=[Top1Accuracy()])\noptimizer.optimize()\noptimizer.set_model(model=model)\ntmp_dir = tempfile.mkdtemp()\noptimizer.set_checkpoint(SeveralIteration(1), tmp_dir)\ntrain_summary = TrainSummary(log_dir=tmp_dir, app_name='run1')\ntrain_summary.set_summary_trigger('LearningRate', SeveralIteration(1))\nval_summary = ValidationSummary(log_dir=tmp_dir, app_name='run1')\noptimizer.set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\noptimizer.set_end_when(MaxEpoch(epoch_num * 2))\ntrained_model = optimizer.optimize()\nlr_result = train_summary.read_scalar('LearningRate')\ntop1_result = val_summary.read_scalar('Top1Accuracy')\nparameters = trained_model.parameters()\nassert parameters['linear1'] is not None\nprint('parameters %s' % parameters['linear1'])\npredict_result = trained_model.predict(trainingData)\np = predict_result.take(2)\nprint('predict predict: \\n')\nfor i in p:\n    print(str(i) + '\\n')\nprint(len(p))\ntest_results = trained_model.evaluate(trainingData, 32, [Top1Accuracy()])\nfor test_result in test_results:\n    print(test_result)\n"
}