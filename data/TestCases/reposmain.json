{
    "functionName": "main",
    "className": null,
    "fileName": "/AlexBdx_&_Heli/10_Executable_&_test_CNN.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "try:\n    with open(PATH_MD_PARAMS) as f:\n        data = csv.DictReader(f)\n        for line in data:\n            params = line\nexcept FileNotFoundError:\n    print('[ERROR] Motion detection parameters file not found.')\n    raise\nparams['iou'] = float(params['iou']) / 2\nparams['gaussWindow'] = int(params['gaussWindow'])\nparams['residualConnections'] = int(params['residualConnections'])\nparams['dilationIterations'] = int(params['dilationIterations'])\nparams['sigma'] = float(params['sigma'])\nprint('[INFO] Motion detection params:\\n', params)\ntry:\n    loaded_model = transfer_learning.load_model(PATH_ARCHITECTURE, PATH_WEIGHTS\n        )\nexcept FileNotFoundError:\n    print('[ERROR] CNN model|weights file not found.')\n    raise\nfirst_bbox = min(bbox_heli_ground_truth.keys())\nlast_bbox = max(bbox_heli_ground_truth.keys())\nprint('[INFO] Using bbox frames {} to {}'.format(first_bbox, last_bbox))\ntiming = {'Read frame': 0, 'Convert to grayscale': 0, 'Stabilize': 0,\n    'Double Gauss': 0, 'Abs diff': [], 'Thresholding': 0, 'Dilation': 0,\n    'Count boxes': 0, 'Finalize': 0}\nnb_bbox = []\nTracker = OPENCV_OBJECT_TRACKERS['csrt']()\nflag_tracker_active = False\nextractor = extract.extractor()\nprevious_gray_frame = collections.deque(maxlen=params['residualConnections'])\nY_prediction = []\nY_test = []\ncounter_bbox = 0\nif REENCODE:\n    reencoded_video = cv2.VideoWriter(PATH_REENCODED_VIDEO, FOURCC, 25, (\n        1920, 1080))\nt0 = time.perf_counter()\nfor frame_number in range(NB_FRAMES):\n    current_frame = VIDEO_STREAM.read()[1]\n    t1 = time.perf_counter()\n    flag_tracker_active = False\n    if flag_tracker_active:\n        flag_success, bbox_roi = Tracker.update(current_frame)\n        bbox_roi = [int(value) for value in bbox_roi]\n        if frame_number % CNN_CHECK_STRIDE == 0:\n            print('[INFO] Verifying tracker at frame', frame_number)\n            prediction, crop = infer_bbox(loaded_model, current_frame,\n                bbox_roi, METHOD)\n            if prediction == 1:\n                flag_quit_program = display_frame(current_frame, bbox_roi,\n                    frame_number, flag_tracker_active)\n                if flag_quit_program:\n                    return\n                continue\n            elif prediction == 0:\n                Tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n                flag_tracker_active = False\n                previous_gray_frame = collections.deque(maxlen=params[\n                    'residualConnections'])\n                pass\n            else:\n                print('[ERROR] The model is supposed to be a binary classifier'\n                    )\n                raise\n        else:\n            flag_quit_program = display_frame(current_frame, bbox_roi,\n                frame_number, flag_tracker_active)\n            if flag_quit_program:\n                return\n            continue\n    else:\n        pass\n    current_gray_frame = cv2.cvtColor(current_frame.copy(), cv2.COLOR_RGB2GRAY)\n    if len(previous_gray_frame) < params['residualConnections']:\n        previous_gray_frame.append(current_gray_frame)\n        continue\n    t4 = time.perf_counter()\n    current_gauss_frame, previous_gauss_frame = gaussian_blur([\n        current_gray_frame, previous_gray_frame[0]], params['gaussWindow'])\n    t5 = time.perf_counter()\n    diff_frame = cv2.absdiff(current_gauss_frame, previous_gauss_frame)\n    t7 = time.perf_counter()\n    canny_frame = canny_contours(diff_frame, params['sigma'])\n    t7 = time.perf_counter()\n    morph_frame = cv2.dilate(canny_frame, None, iterations=params[\n        'dilationIterations'])\n    contours = extractor.image_contour(morph_frame, sorting='area',\n        min_area=MIN_AREA)\n    t8 = time.perf_counter()\n    large_box = 0\n    counter_bbox_heli = 0\n    if first_bbox <= frame_number <= last_bbox:\n        x_gt, y_gt, w_gt, h_gt = bbox_heli_ground_truth[frame_number]\n    else:\n        x_gt, y_gt, w_gt, h_gt = 1919, 1079, 1, 1\n    counter_failed_detection = 0\n    x, y, w, h = 0, 0, 0, 0\n    success = []\n    for contour in contours:\n        c = contour[0]\n        if cv2.contourArea(c) < MIN_AREA:\n            continue\n        if cv2.contourArea(c) > MAX_AREA:\n            continue\n        x, y, w, h = cv2.boundingRect(c)\n        if x < 0 or x + w > FRAME_WIDTH or y < 0 or y + h > FRAME_HEIGHT:\n            continue\n        if not (PADDING < x + w // 2 < FRAME_WIDTH - PADDING and PADDING < \n            y + h // 2 < FRAME_HEIGHT - PADDING):\n            continue\n        large_box += 1\n        counter_bbox += 1\n        prediction, crop = infer_bbox(loaded_model, current_frame, (x, y, w,\n            h), METHOD)\n        converted_bbox = bbox.xywh_to_x1y1x2y2((x, y, w, h))\n        converted_gt_bbox = bbox.xywh_to_x1y1x2y2((x_gt, y_gt, w_gt, h_gt))\n        label = 1 if bbox.intersection_over_union(converted_bbox,\n            converted_gt_bbox) >= params['iou'] else 0\n        Y_prediction.append(prediction)\n        Y_test.append(label)\n        name = 'Helico' if prediction else 'Motion'\n        color = COLOR['RED'] if prediction else COLOR['BLUE']\n        cv2.putText(current_frame, name, (x, y - 10), cv2.\n            FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n        cv2.rectangle(current_frame, (x, y), (x + w, y + h), color, 2)\n    previous_gray_frame.append(current_gray_frame)\n    text_bboxes = 'Number of detected bboxes: {}'.format(counter_bbox)\n    cv2.putText(current_frame, text_bboxes, (10, 80), cv2.\n        FONT_HERSHEY_SIMPLEX, 0.5, COLOR['WHITE'], 2)\n    if len(Y_test):\n        conf_mx = confusion_matrix(Y_test, Y_prediction)\n        if conf_mx.shape == (2, 2):\n            accuracy = (conf_mx[0, 0] + conf_mx[1, 1]) / np.sum(conf_mx)\n        else:\n            conf_mx = np.zeros((2, 2))\n            accuracy = 1\n    else:\n        conf_mx = np.zeros((2, 2))\n        accuracy = 1\n    text_accuracy = (\n        'Cumulative accuracy: {:.1f} % TN: {} TP: {} FN: {} FP: {}'.format(\n        100 * accuracy, conf_mx[0, 0], conf_mx[1, 1], conf_mx[1, 0],\n        conf_mx[0, 1]))\n    cv2.putText(current_frame, text_accuracy, (10, 60), cv2.\n        FONT_HERSHEY_SIMPLEX, 0.5, COLOR['WHITE'], 2)\n    tracker_state = 'ON' if flag_tracker_active else 'OFF'\n    text_tracker = 'Tracker: {}'.format(tracker_state)\n    cv2.putText(current_frame, text_tracker, (10, 40), cv2.\n        FONT_HERSHEY_SIMPLEX, 0.5, COLOR['WHITE'], 2)\n    fps = 1 / (time.perf_counter() - t0)\n    text_count = 'FPS: {:.1f} Frame number: {}'.format(fps, frame_number)\n    cv2.putText(current_frame, text_count, (10, 20), cv2.\n        FONT_HERSHEY_SIMPLEX, 0.5, COLOR['WHITE'], 2)\n    t0 = time.perf_counter()\n    if REENCODE:\n        reencoded_video.write(current_frame)\n    cv2.imshow(VIDEO_STREAM_PATH, imutils.resize(current_frame, width=1000))\n    key = cv2.waitKey(1) & 255\n    if key == ord('q'):\n        if REENCODE:\n            reencoded_video.release()\n        return\n    \"\"\"\n            print(\"[INFO] Inferred bbox: \", prediction)\n            if prediction == 1:  # First helico detected!\n                #Tracker.init(current_frame, (x, y, w, h))\n                #flag_tracker_active = True\n                #success.append([prediction, crop])\n                \n                #break\n                #continue\n            elif prediction == 0:\n                counter_failed_detection += 1\n                if counter_failed_detection >= MAX_FAILED_INFERENCES:\n                    #break  # Not time for another attempt. Improve the motion detection.\n                    #continue\n            else:\n                print(\"[ERROR] The model is supposed to be a binary classifier\")\n\n        print(\"[INFO] Length success:\", len(success))\n        if len(success):\n            fig, ax = plt.subplots(1, max(2, len(success)))\n            print(len(success))\n            for index, res in enumerate(success):\n                print(index)\n                ax[index].imshow(cv2.cvtColor(res[1], cv2.COLOR_BGR2RGB))\n                ax[index].set_title(\"Heli\")\n                ax[index].axis('off')\n            plt.show()\n        \"\"\"\n    \"\"\"[Is display_frame still useful?]\n        # Display the result from motion detection\n        #print(\"[INFO] Display frame\")\n        #flag_quit_program = display_frame(current_frame, (x, y, w, h), frame_number, flag_tracker_active)\n        \n        print()\n        \n        if flag_quit_program:\n            return\n        \"\"\"\n    \"\"\"[For later]\n        # Classify bboxes based on their IOU with ground truth\n        converted_current_bbox = bbox.xywh_to_x1y1x2y2(bbox_crop)\n        converted_ground_truth_bbox = bbox.xywh_to_x1y1x2y2((x_gt, y_gt, w_gt, h_gt))\n        if bbox.intersection_over_union(converted_current_bbox, converted_ground_truth_bbox) >= IOU:\n            counter_bbox_heli += 1\n        \"\"\"\nconf_mx = confusion_matrix(Y_test, Y_prediction)\nprint('[INFO] Confusion Matrix:\\n', conf_mx)\nplt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.title('Confusion matrix on {} | Accuracy: {:.1f}%'.format(FOLDER_NAME, \n    100 * accuracy))\nplt.savefig('Confusion_matrix_' + FOLDER_NAME, tight_layout=False)\nplt.show()\nif REENCODE:\n    reencoded_video.release()\n"
}