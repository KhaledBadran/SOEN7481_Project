{
    "functionName": "test_classic_walkforward_crossvalidation_split",
    "className": null,
    "fileName": "/Neuraxio_&_Neuraxle/testing_&_metaopt_&_test_random.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "np.random.seed(10)\nbatch_size = 7\ntime_series_size = 20\nfeatures_size = 2\nvalidation_window_size_temp = validation_window_size\nif validation_window_size is None:\n    validation_window_size_temp = training_window_size\nif drop_remainder:\n    number_of_fold = math.floor((time_series_size - training_window_size -\n        padding_between_training_and_validation) / validation_window_size_temp)\nelse:\n    number_of_fold = math.ceil((time_series_size - training_window_size -\n        padding_between_training_and_validation) / validation_window_size_temp)\nremainder_size = (time_series_size - training_window_size -\n    padding_between_training_and_validation) % validation_window_size_temp\nif remainder_size == 0:\n    remainder_size = validation_window_size_temp\ndata_inputs = np.random.randint(low=0, high=1, size=(batch_size,\n    time_series_size, features_size)).astype(np.float)\nexpected_outputs = np.random.randint(low=0, high=1, size=(batch_size,\n    time_series_size, features_size)).astype(np.float)\nstep = WalkForwardTimeSeriesCrossValidationWrapper(validation_window_size=\n    validation_window_size, training_window_size=training_window_size,\n    padding_between_training_and_validation=\n    padding_between_training_and_validation, drop_remainder=drop_remainder)\n(train_data_inputs, train_expected_outputs, validation_data_inputs,\n    validation_expected_outputs) = step.split(data_inputs, expected_outputs)\nassert len(train_data_inputs) == number_of_fold\nassert len(train_expected_outputs) == number_of_fold\nassert len(validation_data_inputs) == number_of_fold\nassert len(validation_expected_outputs) == number_of_fold\nassert train_data_inputs[0].shape == (batch_size, training_window_size,\n    features_size)\nassert train_expected_outputs[0].shape == (batch_size, training_window_size,\n    features_size)\nassert validation_data_inputs[0].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert validation_expected_outputs[0].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert train_data_inputs[1].shape == (batch_size, training_window_size,\n    features_size)\nassert train_expected_outputs[1].shape == (batch_size, training_window_size,\n    features_size)\nassert validation_data_inputs[1].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert validation_expected_outputs[1].shape == (batch_size,\n    validation_window_size_temp, features_size)\nif drop_remainder:\n    assert train_data_inputs[-1].shape == (batch_size, training_window_size,\n        features_size)\n    assert train_expected_outputs[-1].shape == (batch_size,\n        training_window_size, features_size)\n    assert validation_data_inputs[-1].shape == (batch_size,\n        validation_window_size_temp, features_size)\n    assert validation_expected_outputs[-1].shape == (batch_size,\n        validation_window_size_temp, features_size)\nelse:\n    assert train_data_inputs[-1].shape == (batch_size, training_window_size,\n        features_size)\n    assert train_expected_outputs[-1].shape == (batch_size,\n        training_window_size, features_size)\n    assert validation_data_inputs[-1].shape == (batch_size, remainder_size,\n        features_size)\n    assert validation_expected_outputs[-1].shape == (batch_size,\n        remainder_size, features_size)\npytest.mark.parametrize(\n    'training_window_size, validation_window_size, padding_between_training_and_validation, drop_remainder'\n    , classic_walforward_parameters)"
}