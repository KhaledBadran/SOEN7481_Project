{
    "functionName": "test_load_optim_method",
    "className": "TestSimple",
    "fileName": "/intel-analytics_&_Bigdl/pyspark_&_test_&_bigdl_&_test_simple_integration.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "FEATURES_DIM = 2\ndata_len = 100\nbatch_size = 32\nepoch_num = 5\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, FEATURES_DIM)\n    label = (2 * features).sum() + 0.4\n    return Sample.from_ndarray(features, label)\ntrainingData = self.sc.parallelize(range(0, data_len)).map(lambda i:\n    gen_rand_sample())\nmodel = Sequential()\nl1 = Linear(FEATURES_DIM, 1).set_init_method(Xavier(), Zeros()).set_name(\n    'linear1')\nmodel.add(l1)\nsgd = SGD(learningrate=0.01, learningrate_decay=0.0002, weightdecay=0.0,\n    momentum=0.0, dampening=0.0, nesterov=False, leaningrate_schedule=Poly(\n    0.5, int(data_len / batch_size * epoch_num)))\ntmp_path = tempfile.mktemp()\nsgd.save(tmp_path, True)\noptim_method = OptimMethod.load(tmp_path)\nassert optim_method.learningRate() == sgd.value.learningRate()\nassert optim_method.momentum() == sgd.value.momentum()\nassert optim_method.nesterov() == sgd.value.nesterov()\noptimizer = Optimizer(model=model, training_rdd=trainingData, criterion=\n    MSECriterion(), optim_method=optim_method, end_trigger=MaxEpoch(\n    epoch_num), batch_size=batch_size)\noptimizer.optimize()\n"
}