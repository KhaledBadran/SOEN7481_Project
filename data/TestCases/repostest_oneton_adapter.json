{
    "functionName": "test_oneton_adapter",
    "className": null,
    "fileName": "/Accenture_&_AmpliGraph/tests_&_ampligraph_&_datasets_&_test_datasets.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "from ampligraph.evaluation.protocol import create_mappings, to_idx\nX = np.array([['a', 'p', 'b'], ['a', 'p', 'd'], ['c', 'p', 'd'], ['c', 'p',\n    'e'], ['c', 'p', 'f']])\nO = np.array([[0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 1, 1]])\nT = np.array([['a', 'p', 'c'], ['c', 'p', 'b']])\nOT1 = np.array([[0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 1, 1]]),\nOT2 = np.array([[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0]]),\nfilter = np.concatenate((X, T))\nOF = np.array([[0, 1, 1, 1, 0, 0], [0, 1, 0, 1, 1, 1]])\nOF_map = {(0, 0): [0, 1, 1, 1, 0, 0], (2, 0): [0, 1, 0, 1, 1, 1]}\nrel_to_idx, ent_to_idx = create_mappings(X)\nX = to_idx(X, ent_to_idx, rel_to_idx)\nadapter = OneToNDatasetAdapter()\nadapter.use_mappings(rel_to_idx, ent_to_idx)\nadapter.set_data(X, 'train', mapped_status=True)\nadapter.set_data(T, 'test', mapped_status=False)\nassert adapter.mapped_status['test'] == True\ntrain_output_map = adapter.generate_output_mapping('train')\nunique_sp = set([(s, p) for s, p in X[:, ([0, 1])]])\nfor sp in train_output_map.keys():\n    assert sp in unique_sp\nwith pytest.raises(ValueError):\n    adapter.generate_outputs('train')\nadapter.set_output_mapping(train_output_map)\nadapter.generate_outputs('train')\ntrain_iter = adapter.get_next_batch(batches_count=1, dataset_type='train',\n    use_filter=False)\ntriples, onehot = next(train_iter)\nassert np.all(np.unique(X[:, ([0, 1])], axis=0) == triples[:, ([0, 1])])\nassert np.all(O == onehot)\ntest_iter = adapter.get_next_batch(batches_count=1, dataset_type='test',\n    use_filter=False)\ntriples, onehot = next(test_iter)\nassert np.all(np.unique(X[:, ([0, 1])], axis=0) == triples[:, ([0, 1])])\nassert np.all(OT1 == onehot)\ntest_output_map = adapter.generate_output_mapping('test')\nadapter.set_output_mapping(test_output_map)\ntest_iter = adapter.get_next_batch(batches_count=1, dataset_type='test',\n    use_filter=False)\ntriples, onehot = next(test_iter)\nassert np.all(np.unique(X[:, ([0, 1])], axis=0) == triples[:, ([0, 1])])\nassert np.all(OT2 == onehot)\nadapter.set_filter(filter_triples=filter)\ntrain_iter = adapter.get_next_batch(batches_count=1, dataset_type='train',\n    use_filter=True)\ntriples, onehot = next(train_iter)\nassert np.all(np.unique(X[:, ([0, 1])], axis=0) == triples[:, ([0, 1])])\nassert np.all(OF == onehot)\nassert len(adapter.filtered_status) > 0\nadapter.clear_outputs()\nassert len(adapter.filtered_status) == 0\nadapter.clear_outputs()\nadapter.generate_outputs('train', use_filter=False, unique_pairs=False)\nassert adapter.verify_outputs('train', use_filter=False, unique_pairs=False\n    ) == True\nassert adapter.verify_outputs('train', use_filter=True, unique_pairs=True\n    ) == False\nassert adapter.verify_outputs('train', use_filter=True, unique_pairs=False\n    ) == False\nassert adapter.verify_outputs('train', use_filter=False, unique_pairs=True\n    ) == False\nadapter.clear_outputs()\nadapter.generate_outputs('train', use_filter=True, unique_pairs=True)\nassert adapter.verify_outputs('train', use_filter=False, unique_pairs=False\n    ) == False\nassert adapter.verify_outputs('train', use_filter=True, unique_pairs=True\n    ) == True\nassert adapter.verify_outputs('train', use_filter=True, unique_pairs=False\n    ) == False\nassert adapter.verify_outputs('train', use_filter=False, unique_pairs=True\n    ) == False\nadapter.clear_outputs()\ntrain_iter = adapter.get_next_batch(batches_count=1, dataset_type='train',\n    use_filter=True, unique_pairs=True)\nout, triples = next(train_iter)\nassert out.shape[0] == 2\nassert triples.shape[0] == 2\nadapter.clear_outputs()\ntrain_iter = adapter.get_next_batch(batches_count=1, dataset_type='train',\n    use_filter=True, unique_pairs=False)\nout, triples = next(train_iter)\nassert out.shape[0] == 5\nassert triples.shape[0] == 5\nbatch_size = 3\nbatch_iter = adapter.get_next_batch_subject_corruptions(batch_size=\n    batch_size, dataset_type='train', use_filter=True)\ntriples, out, out_onehot = next(batch_iter)\nassert np.all(X == triples)\nassert triples.shape[1] == 3\nassert out.shape[1] == 3\nassert out.shape[0] == batch_size\nassert out_onehot.shape[0] == batch_size\nassert out_onehot.shape[0] == out.shape[0]\nassert out_onehot.shape[1] == len(adapter.ent_to_idx)\nadapter.clear_outputs()\nbatch_iter = adapter.get_next_batch_subject_corruptions(batch_size=-1,\n    dataset_type='train', use_filter=True)\ntriples, out, out_onehot = next(batch_iter)\nassert np.all(X == triples)\nassert triples.shape[1] == 3\nassert out.shape[1] == 3\nassert out.shape[0] == len(adapter.ent_to_idx)\nassert out_onehot.shape[0] == out_onehot.shape[1]\nassert out_onehot.shape[0] == out.shape[0]\nassert out_onehot.shape[1] == len(adapter.ent_to_idx)\nfor idx, (s, p, o) in enumerate(out):\n    if (s, p) in OF_map.keys():\n        onehot = OF_map[s, p]\n        assert np.all(onehot == out_onehot[idx])\n    else:\n        assert np.all(out_onehot[idx] == 0)\n"
}