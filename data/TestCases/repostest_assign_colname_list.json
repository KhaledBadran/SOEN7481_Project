{
    "functionName": "test_assign_colname_list",
    "className": "TestMillionRows",
    "fileName": "/kenfar_&_DataGristle/scripts_&_tests_&_test_gristle_differ_cmd_slow.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\"\n        \"\"\"\nfile1 = pjoin(self.temp_dir, 'old.csv')\nfile2 = pjoin(self.temp_dir, 'new.csv')\nconfig = Config(self.temp_dir)\nconfig.add_property({'delimiter': ','})\nconfig.add_property({'has_header': False})\nconfig.add_property({'quoting': csv.QUOTE_NONE})\nconfig.add_property({'col_names': sorted(FIELDS, key=FIELDS.get)})\nconfig.add_property({'key_cols': ['pkid']})\nconfig.add_property({'ignore_cols': ['vid', 'from_epoch', 'to_epoch',\n    'hostname']})\nconfig.add_property({'temp_dir': self.temp_dir})\nconfig.add_property({'files': [file1, file2]})\nassignments = [['delete', 'del_flag', 'literal', 'd', None, None], [\n    'delete', 'to_epoch', 'special', 'start_epoch', None, None], ['insert',\n    'from_epoch', 'special', 'start_epoch', None, None], ['insert', 'pkid',\n    'sequence', '', 'old', 'pkid'], ['insert', 'vid', 'sequence', '', 'old',\n    'vid'], ['chgold', 'to_epoch', 'special', 'start_epoch', None, None], [\n    'chgnew', 'from_epoch', 'special', 'start_epoch', None, None], [\n    'chgnew', 'pkid', 'copy', '', 'old', 'pkid'], ['chgnew', 'vid',\n    'sequence', '', 'old', 'vid']]\nfor ass in assignments:\n    config.add_assignment(ass[0], ass[1], ass[2], ass[3], ass[4], ass[5])\nconfig.write_config()\nstart_time = int(time.time())\ncmd = (\n    \"\"\" %s\n                  --config-fn %s\n                  --variables 'start_epoch:%s'\n              \"\"\"\n     % (pjoin(script_dir, 'gristle_differ'), config.config_fqfn, start_time))\nrunner = envoy.run(cmd)\nprint(runner.std_out)\nprint(runner.std_err)\nprint('running gristle_differ - starting')\nprint('running gristle_differ - done with duration of %d seconds' % int(\n    time.time() - start_time))\nprint('running assertions     - starting')\nself._print_counts()\nassert runner.status_code == 0\nassert get_file_count(pjoin(self.temp_dir, 'new.csv.insert'), self.dialect\n    ) == self.files.insert_cnt\nassert get_file_count(pjoin(self.temp_dir, 'new.csv.delete'), self.dialect\n    ) == self.files.delete_cnt\nassert get_file_count(pjoin(self.temp_dir, 'new.csv.same'), self.dialect\n    ) == self.files.same_cnt\nassert get_file_count(pjoin(self.temp_dir, 'new.csv.chgold'), self.dialect\n    ) == self.files.chg_cnt\nassert get_file_count(pjoin(self.temp_dir, 'new.csv.chgnew'), self.dialect\n    ) == self.files.chg_cnt\nfor row in csv.reader(fileinput.input(pjoin(self.temp_dir, 'new.csv.delete'\n    )), self.dialect):\n    assert row[6] == 'd'\n    assert row[3] == str(start_time)\nfileinput.close()\nins_pkid_list = []\nins_vid_list = []\nmin_pkid = None\nmin_vid = None\nfor row in csv.reader(fileinput.input(pjoin(self.temp_dir, 'new.csv.insert'\n    )), self.dialect):\n    assert row[FIELDS['from_epoch']] == str(start_time)\n    ins_pkid_list.append(int(row[FIELDS['pkid']]))\n    ins_vid_list.append(int(row[FIELDS['vid']]))\n    min_pkid = get_min_id(min_pkid, row[FIELDS['pkid']])\n    min_vid = get_min_id(min_vid, row[FIELDS['vid']])\n    assert row[FIELDS['del_flag']] == ''\nfileinput.close()\nassert len(ins_pkid_list) == len(get_uniq_seq(ins_pkid_list))\nassert len(ins_vid_list) == len(get_uniq_seq(ins_vid_list))\nassert min_pkid > self.files.old_rec_cnt\nassert min_vid > self.files.old_rec_cnt\nfor row in csv.reader(fileinput.input(pjoin(self.temp_dir, 'new.csv.chgold'\n    )), self.dialect):\n    assert row[FIELDS['to_epoch']] == str(start_time)\n    assert row[FIELDS['del_flag']] == ''\nfileinput.close()\nchgnew_vid_list = []\nfor row in csv.reader(fileinput.input(pjoin(self.temp_dir, 'new.csv.chgnew'\n    )), self.dialect):\n    assert row[FIELDS['from_epoch']] == str(start_time)\n    assert row[FIELDS['del_flag']] == ''\n    chgnew_vid_list.append(int(row[FIELDS['vid']]))\nfileinput.close()\nassert len(set(ins_vid_list).intersection(chgnew_vid_list)\n    ) == 0, 'dup vids across files'\n"
}