{
    "functionName": "multiclass_hinge_loss",
    "className": null,
    "fileName": "/Lasagne_&_Lasagne/lasagne_&_objectives.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "\"\"\"Computes the multi-class hinge loss between predictions and targets.\n\n    .. math:: L_i = \\\\max_{j \\\\not = t_i} (0, p_j - p_{t_i} + \\\\delta)\n\n    Parameters\n    ----------\n    predictions : Theano 2D tensor\n        Predictions in (0, 1), such as softmax output of a neural network,\n        with data points in rows and class probabilities in columns.\n    targets : Theano 2D tensor or 1D tensor\n        Either a vector of int giving the correct class index per data point\n        or a 2D tensor of one-hot encoding of the correct class in the same\n        layout as predictions (non-binary targets in [0, 1] do not work!)\n    delta : scalar, default 1\n        The hinge loss margin\n\n    Returns\n    -------\n    Theano 1D tensor\n        An expression for the item-wise multi-class hinge loss\n\n    Notes\n    -----\n    This is an alternative to the categorical cross-entropy loss for\n    multi-class classification problems\n    \"\"\"\nnum_cls = predictions.shape[1]\nif targets.ndim == predictions.ndim - 1:\n    targets = theano.tensor.extra_ops.to_one_hot(targets, num_cls)\nelif targets.ndim != predictions.ndim:\n    raise TypeError('rank mismatch between targets and predictions')\ncorrects = predictions[targets.nonzero()]\nrest = theano.tensor.reshape(predictions[(1 - targets).nonzero()], (-1, \n    num_cls - 1))\nrest = theano.tensor.max(rest, axis=1)\nreturn theano.tensor.nnet.relu(rest - corrects + delta)\n"
}