{
    "functionName": "create_dataframe",
    "className": "LogToSparkDF",
    "fileName": "/kitware_&_BroThon/zat_&_log_to_sparkdf.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "\"\"\" Create a Spark dataframe from a Bro/Zeek log file\n            Args:\n               log_fllename (string): The full path to the Zeek log\n               fillna (bool): Fill in NA/NaN values (default=True)\n        \"\"\"\n_zeek_reader = zeek_log_reader.ZeekLogReader(log_filename)\n_, field_names, field_types, _ = _zeek_reader._parse_zeek_header(log_filename)\nspark_schema = self.build_spark_schema(field_names, field_types)\n_df = self.spark.read.csv(log_filename, schema=spark_schema, sep='\\t',\n    comment='#', nullValue='-')\n\"\"\" Secondary processing (cleanup)\n            - Fix column names with '.' in them\n            - Fill in Nulls (optional)\n            - timestamp convert\n            - boolean convert\n        \"\"\"\n\"\"\" Note: Yes column names with '.' in them can be escaped with backticks when selecting them BUT\n                  many pipeline operations will FAIL internally if the column names have a '.' in them.\n        \"\"\"\nfixed_columns = list(map(lambda x: x.replace('.', '_'), _df.columns))\n_df = _df.toDF(*fixed_columns)\nif fillna:\n    _df = _df.na.fill(0)\n    _df = _df.na.fill('-')\nfor name, f_type in zip(field_names, field_types):\n    ref_name = name.replace('.', '_')\n    if f_type == 'time':\n        _df = _df.withColumn(name, _df[ref_name].cast('timestamp'))\n    if f_type == 'bool':\n        _df = _df.withColumn(name, when(col(ref_name) == 'T', 'true').when(\n            col(ref_name) == 'F', 'false').otherwise('null').cast('boolean'))\nreturn _df\n"
}