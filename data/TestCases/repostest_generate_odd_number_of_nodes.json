{
    "functionName": "test_generate_odd_number_of_nodes",
    "className": null,
    "fileName": "/bio-phys_&_MDBenchmark/mdbenchmark_&_tests_&_test_generate.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\"Make sure we generate the correct folder structure.\"\"\"\nwith tmpdir.as_cwd():\n    for ext in extensions:\n        open('protein.{}'.format(ext), 'a').close()\n    monkeypatch.setattr('mdbenchmark.mdengines.get_available_modules', lambda :\n        {'gromacs': ['2016'], 'namd': ['11']})\n    result = cli_runner.invoke(cli, ['generate', '--module={}'.format(\n        module), '--host=draco', '--min-nodes=6', '--max-nodes=8', '--gpu',\n        '--no-cpu', '--name=protein', '--yes'])\n    output1 = 'Creating benchmark system for {} with GPUs.\\n'.format(module)\n    bundle = dtr.discover()\n    df = DataFrameFromBundle(bundle)\n    df = ConsolidateDataFrame(df)\n    test_output = 'Benchmark Summary:\\n' + PrintDataFrame(df, False) + '\\n'\n    output2 = \"\"\"Generating the above benchmarks.\nFinished generating all benchmarks.\nYou can now submit the jobs with mdbenchmark submit.\n\"\"\"\n    if 'namd' in module:\n        output = NAMD_WARNING_FORMATTED + output1 + test_output + output2\n    else:\n        output = output1 + test_output + output2\n    assert result.exit_code == 0\n    assert result.output == output\n    assert os.path.exists('draco_{}'.format(engine))\n    host_engine_version_path = 'draco_{}/{}_gpu/'.format(engine, version)\n    for i in range(6, 9):\n        assert os.path.exists(host_engine_version_path + '{}'.format(i))\n        for ext in extensions:\n            assert os.path.exists(host_engine_version_path +\n                '{}/protein.{}'.format(i, ext))\n        assert os.path.exists(host_engine_version_path + '{}/bench.job'.\n            format(i))\npytest.mark.parametrize('engine, module, version, extensions', [('gromacs',\n    'gromacs/2016', '2016', ['tpr']), ('namd', 'namd/11', '11', ['namd',\n    'pdb', 'psf'])])"
}