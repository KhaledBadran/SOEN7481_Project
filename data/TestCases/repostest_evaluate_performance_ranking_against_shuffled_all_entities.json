{
    "functionName": "test_evaluate_performance_ranking_against_shuffled_all_entities",
    "className": null,
    "fileName": "/Accenture_&_AmpliGraph/tests_&_ampligraph_&_evaluation_&_test_protocol.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\" Compares mrr of test set by using default protocol against all entities vs \n        mrr of corruptions generated by corrupting using entities_subset = all entities shuffled\n    \"\"\"\nimport random\nX = load_wn18()\nmodel = ComplEx(batches_count=10, seed=0, epochs=1, k=20, eta=10, loss=\n    'nll', regularizer=None, optimizer='adam', optimizer_params={'lr': 0.01\n    }, verbose=True)\nmodel.fit(X['train'])\nX_filter = np.concatenate((X['train'], X['valid'], X['test']))\nentities_subset = random.shuffle(list(model.ent_to_idx.keys()))\nfrom ampligraph.evaluation import hits_at_n_score, mrr_score, mr_score\nranks_all = evaluate_performance(X['test'][::1000], model, X_filter,\n    verbose=True, corrupt_side='s,o')\nranks_suffled_ent = evaluate_performance(X['test'][::1000], model, X_filter,\n    verbose=True, corrupt_side='s,o', entities_subset=entities_subset)\nassert mrr_score(ranks_all) == mrr_score(ranks_suffled_ent)\n"
}