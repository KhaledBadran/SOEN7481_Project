{
    "functionName": "test_LIME",
    "className": "TestLIMEExplainer",
    "fileName": "/IBM_&_AIX360/tests_&_lime_&_test_lime.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "iris = sklearn.datasets.load_iris()\ntrain, test, labels_train, labels_test = (sklearn.model_selection.\n    train_test_split(iris.data, iris.target, train_size=0.8))\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\nrf.fit(train, labels_train)\nsklearn.metrics.accuracy_score(labels_test, rf.predict(test))\nexplainer = LimeTabularExplainer(train, feature_names=iris.feature_names,\n    class_names=iris.target_names, discretize_continuous=True)\ni = 19\nexplanation = explainer.explain_instance(test[i], rf.predict_proba,\n    num_features=2, top_labels=1)\nprint(i, explanation.as_map())\nprint('Invoked Tabular explainer\\n')\nnewsgroups_train = fetch_20newsgroups(subset='train')\nnewsgroups_test = fetch_20newsgroups(subset='test')\nclass_names = [(x.split('.')[-1] if 'misc' not in x else '.'.join(x.split(\n    '.')[-2:])) for x in newsgroups_train.target_names]\nclass_names[3] = 'pc.hardware'\nclass_names[4] = 'mac.hardware'\nprint(','.join(class_names))\nvectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\ntrain_vectors = vectorizer.fit_transform(newsgroups_train.data)\ntest_vectors = vectorizer.transform(newsgroups_test.data)\nnb = MultinomialNB(alpha=0.01)\nnb.fit(train_vectors, newsgroups_train.target)\npred = nb.predict(test_vectors)\nsklearn.metrics.f1_score(newsgroups_test.target, pred, average='weighted')\nc = make_pipeline(vectorizer, nb)\nprint(c.predict_proba([newsgroups_test.data[0]]).round(3))\nexplainer = LimeTextExplainer(class_names=class_names)\nidx = 1340\nexp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba,\n    num_features=6, labels=[0, 17])\nprint('Document id: %d' % idx)\nprint('Predicted class =', class_names[nb.predict(test_vectors[idx]).\n    reshape(1, -1)[0, 0]])\nprint('True class: %s' % class_names[newsgroups_test.target[idx]])\nprint('Explanation for class %s' % class_names[0])\nprint('\\n'.join(map(str, exp.as_list(label=0))))\nprint()\nprint('Explanation for class %s' % class_names[17])\nprint('\\n'.join(map(str, exp.as_list(label=17))))\nprint('Invoked Text explainer\\n')\nmnist = fetch_openml('mnist_784')\nX_vec = np.stack([gray2rgb(iimg) for iimg in mnist.data.reshape((-1, 28, 28\n    ))], 0)\ny_vec = mnist.target.astype(np.uint8)\nclass PipeStep(object):\n    \"\"\"\n            Wrapper for turning functions into pipeline transforms (no-fitting)\n            \"\"\"\n\n    def __init__(self, step_func):\n        self._step_func = step_func\n\n    def fit(self, *args):\n        return self\n\n    def transform(self, X):\n        return self._step_func(X)\nmakegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\nflatten_step = PipeStep(lambda img_list: [img.ravel() for img in img_list])\nsimple_rf_pipeline = Pipeline([('Make Gray', makegray_step), (\n    'Flatten Image', flatten_step), ('RF', RandomForestClassifier())])\nX_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec,\n    train_size=0.55)\nsimple_rf_pipeline.fit(X_train, y_train)\nexplainer = LimeImageExplainer(verbose=False)\nsegmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200,\n    ratio=0.2)\nexplanation = explainer.explain_instance(X_test[0], classifier_fn=\n    simple_rf_pipeline.predict_proba, top_labels=10, hide_color=0,\n    num_samples=10000, segmentation_fn=segmenter)\nprint('Invoked Image explainer\\n')\n"
}