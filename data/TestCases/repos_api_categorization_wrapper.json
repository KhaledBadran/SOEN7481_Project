{
    "functionName": "_api_categorization_wrapper",
    "className": null,
    "fileName": "/FreeDiscovery_&_FreeDiscovery/freediscovery_&_server_&_tests_&_test_categorization.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "cv = cv == 'cv'\nif 'CIRCLECI' in os.environ and cv == 1 and solver in ['LinearSVC', 'xgboost']:\n    raise SkipTest\nif solver.startswith('Nearest'):\n    dsid, lsi_id, _, ds_input = get_features_lsi_cached(app, n_categories=\n        n_categories)\n    parent_id = lsi_id\nelse:\n    dsid, _, ds_input = get_features_cached(app, n_categories=n_categories)\n    lsi_id = None\n    parent_id = dsid\nmethod = V01 + '/feature-extraction/{}'.format(dsid)\ndata = app.get_check(method)\ncategories_list = list({row['category'] for row in ds_input['dataset']})\nif n_categories_train is None:\n    training_set = ds_input['training_set']\nelse:\n    assert n_categories_train <= n_categories\n    training_set = list(filter(lambda x: x['category'] in categories_list[:\n        n_categories_train], ds_input['training_set']))\npars = {'parent_id': parent_id, 'data': training_set, 'method': solver,\n    'cv': cv, 'training_scores': True}\nmethod = V01 + '/categorization/'\ntry:\n    data = app.post_check(method, json=pars)\nexcept OptionalDependencyMissing:\n    raise SkipTest\nassert dict2type(data) == {'id': 'str', 'training_scores': {'recall':\n    'float', 'f1': 'float', 'precision': 'float', 'roc_auc': 'float',\n    'average_precision': 'float', 'recall_at_20p': 'float'}}\ntraining_scores = data['training_scores']\nif n_categories_train == 1:\n    if sklearn_version < (0, 18, 0):\n        pass\n    else:\n        assert training_scores['f1'] > 0.99\nelif n_categories == 2:\n    assert training_scores['average_precision'] > 0.73\n    if solver == 'NearestNeighbor':\n        assert training_scores['roc_auc'] > 0.7\n    else:\n        assert training_scores['roc_auc'] >= 0.5\nelif n_categories == 3 and solver == 'NearestNeighbor':\n    assert training_scores['f1'] > 0.6\nelse:\n    assert training_scores['f1'] > 0.3\nmid = data['id']\nmethod = V01 + '/categorization/{}'.format(mid)\ndata = app.get_check(method)\nfor key in ['method']:\n    assert pars[key] == data[key]\nmethod = V01 + '/categorization/{}/predict'.format(mid)\nif max_results:\n    json_data = {'max_results': max_results}\nelse:\n    json_data = {}\njson_data['subset'] = subset\njson_data['metric'] = metric\ndata = app.get_check(method, json=json_data)\ndata = data['data']\nresponse_ref = {'document_id': 'int', 'scores': [{'category': 'str',\n    'score': 'float'}]}\nif solver == 'NearestNeighbor':\n    response_ref['scores'][0]['document_id'] = 'int'\nif max_results is None:\n    if subset == 'all':\n        assert len(data) == len(ds_input['dataset'])\n    elif subset == 'train':\n        assert len(data) == len(training_set)\n    elif subset == 'test':\n        assert len(data) == len(ds_input['dataset']) - len(training_set)\n    else:\n        raise ValueError\nfor row in data:\n    assert dict2type(row) == response_ref\nif solver == 'NearestNeighbor':\n    training_document_id = np.array([row['document_id'] for row in\n        training_set])\n    training_document_id_res = np.array([row['scores'][0]['document_id'] for\n        row in data])\n    assert_equal(np.in1d(training_document_id_res, training_document_id), True)\nmethod = V01 + '/metrics/categorization'\ndata = app.post_check(method, json={'y_true': ds_input['dataset'], 'y_pred':\n    data})\nassert dict2type(data) == {'precision': 'float', 'recall': 'float', 'f1':\n    'float', 'roc_auc': 'float', 'average_precision': 'float',\n    'recall_at_20p': 'float'}\nif n_categories == 2:\n    assert data['average_precision'] > 0.7\n    assert data['roc_auc'] > 0.7\n    assert data['recall_at_20p'] > 0.2\nelif sklearn_version <= (0, 18, 0) and n_categories_train == 1:\n    pass\nelse:\n    assert data['f1'] > 0.32\nmethod = V01 + '/categorization/{}'.format(mid)\nres = app.delete_check(method)\n"
}