{
    "functionName": "binary_crossentropy",
    "className": null,
    "fileName": "/Lasagne_&_Lasagne/lasagne_&_objectives.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "\"\"\"Computes the binary cross-entropy between predictions and targets.\n\n    .. math:: L = -t \\\\log(p) - (1 - t) \\\\log(1 - p)\n\n    Parameters\n    ----------\n    predictions : Theano tensor\n        Predictions in (0, 1), such as sigmoidal output of a neural network.\n    targets : Theano tensor\n        Targets in [0, 1], such as ground truth labels.\n\n    Returns\n    -------\n    Theano tensor\n        An expression for the element-wise binary cross-entropy.\n\n    Notes\n    -----\n    This is the loss function of choice for binary classification problems\n    and sigmoid output units.\n    \"\"\"\npredictions, targets = align_targets(predictions, targets)\nreturn theano.tensor.nnet.binary_crossentropy(predictions, targets)\n"
}