{
    "functionName": "test_expected_improvement_and_gradient",
    "className": "TestExpectedImprovement",
    "fileName": "/Yelp_&_MOE/moe_&_tests_&_optimal_learning_&_python_&_python_version_&_expected_improvement_test.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\"Test EI by comparing the vectorized and \"naive\" versions.\n\n        With the same RNG state, these two functions should return identical output.\n        We use a fairly low number of monte-carlo iterations since we are not\n        trying to converge; just check for consistency.\n\n        .. Note:: this is not a particularly good test. It relies on the \"naive\"\n          version being easier to verify manually and only checks for consistency\n          between the naive and vectorized versions.\n\n        \"\"\"\nnum_points_p_q_list = (1, 0), (1, 1), (2, 1), (1, 4), (5, 3)\nei_tolerance = 10.0 * numpy.finfo(numpy.float64).eps\ngrad_ei_tolerance = 1e-13\nnumpy.random.seed(78532)\nfor test_case in self.gp_test_environments:\n    domain, gaussian_process = test_case\n    for num_to_sample, num_being_sampled in num_points_p_q_list:\n        points_to_sample = domain.generate_uniform_random_points_in_domain(\n            num_to_sample)\n        points_being_sampled = domain.generate_uniform_random_points_in_domain(\n            num_being_sampled)\n        union_of_points = numpy.reshape(numpy.append(points_to_sample,\n            points_being_sampled), (num_to_sample + num_being_sampled, self\n            .dim))\n        ei_eval = ExpectedImprovement(gaussian_process, points_to_sample,\n            points_being_sampled=points_being_sampled, num_mc_iterations=\n            self.num_mc_iterations)\n        mu_star = ei_eval._gaussian_process.compute_mean_of_points(\n            union_of_points)\n        var_star = ei_eval._gaussian_process.compute_variance_of_points(\n            union_of_points)\n        rng_state = numpy.random.get_state()\n        numpy.random.seed(self.rng_seed)\n        ei_vectorized = ei_eval._compute_expected_improvement_monte_carlo(\n            mu_star, var_star)\n        numpy.random.seed(self.rng_seed)\n        ei_naive = ei_eval._compute_expected_improvement_monte_carlo_naive(\n            mu_star, var_star)\n        self.assert_scalar_within_relative(ei_vectorized, ei_naive,\n            ei_tolerance)\n        grad_mu = ei_eval._gaussian_process.compute_grad_mean_of_points(\n            union_of_points, num_derivatives=num_to_sample)\n        grad_chol_decomp = (ei_eval._gaussian_process.\n            compute_grad_cholesky_variance_of_points(union_of_points,\n            num_derivatives=num_to_sample))\n        numpy.random.seed(self.rng_seed)\n        grad_ei_vectorized = (ei_eval.\n            _compute_grad_expected_improvement_monte_carlo(mu_star,\n            var_star, grad_mu, grad_chol_decomp))\n        numpy.random.seed(self.rng_seed)\n        grad_ei_naive = (ei_eval.\n            _compute_grad_expected_improvement_monte_carlo_naive(mu_star,\n            var_star, grad_mu, grad_chol_decomp))\n        self.assert_vector_within_relative(grad_ei_vectorized,\n            grad_ei_naive, grad_ei_tolerance)\n        numpy.random.set_state(rng_state)\n"
}