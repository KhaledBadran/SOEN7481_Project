{
    "functionName": "test_KnowledgeGradient",
    "className": "KnowledgeGradientTest",
    "fileName": "/facebook_&_Ax/ax_&_models_&_tests_&_test_botorch_kg.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "model = KnowledgeGradient()\nmodel.fit(Xs=self.Xs, Ys=self.Ys, Yvars=self.Yvars, bounds=self.bounds,\n    feature_names=self.feature_names, metric_names=self.metric_names,\n    task_features=[], fidelity_features=[])\nn = 2\nX_dummy = torch.rand(1, n, 4, dtype=self.dtype, device=self.device)\nacq_dummy = torch.tensor(0.0, dtype=self.dtype, device=self.device)\nwith mock.patch(self.optimize_acqf) as mock_optimize_acqf:\n    mock_optimize_acqf.side_effect = [(X_dummy, acq_dummy)]\n    Xgen, wgen, _, __ = model.gen(n=n, bounds=self.bounds,\n        objective_weights=self.objective_weights, outcome_constraints=None,\n        linear_constraints=None, model_gen_options={\n        'acquisition_function_kwargs': self.acq_options, 'optimizer_kwargs':\n        self.optimizer_options})\n    self.assertTrue(torch.equal(Xgen, X_dummy.cpu()))\n    self.assertTrue(torch.equal(wgen, torch.ones(n, dtype=self.dtype)))\n    mock_optimize_acqf.assert_called_once()\nini_dummy = torch.rand(10, 32, 3, dtype=self.dtype, device=self.device)\noptimizer_options2 = {'num_restarts': 1, 'raw_samples': 1, 'maxiter': 5,\n    'batch_limit': 1, 'partial_restarts': 2}\nwith mock.patch('ax.models.torch.botorch_kg.gen_one_shot_kg_initial_conditions'\n    , return_value=ini_dummy) as mock_warmstart_initialization:\n    Xgen, wgen, _, __ = model.gen(n=n, bounds=self.bounds,\n        objective_weights=self.objective_weights, outcome_constraints=None,\n        linear_constraints=None, model_gen_options={\n        'acquisition_function_kwargs': self.acq_options, 'optimizer_kwargs':\n        optimizer_options2})\n    mock_warmstart_initialization.assert_called_once()\nobj = ScalarizedObjective(weights=self.objective_weights)\ndummy_acq = PosteriorMean(model=model.model, objective=obj)\nwith mock.patch('ax.models.torch.utils.PosteriorMean', return_value=dummy_acq\n    ) as mock_posterior_mean:\n    Xgen, wgen, _, __ = model.gen(n=n, bounds=self.bounds,\n        objective_weights=self.objective_weights, outcome_constraints=None,\n        linear_constraints=None, model_gen_options={\n        'acquisition_function_kwargs': self.acq_options, 'optimizer_kwargs':\n        optimizer_options2})\n    self.assertEqual(mock_posterior_mean.call_count, 2)\nxbest = model.best_point(bounds=self.bounds, objective_weights=self.\n    objective_weights)\nlb = torch.tensor([b[0] for b in self.bounds]) - 1e-05\nub = torch.tensor([b[1] for b in self.bounds]) + 1e-05\nself.assertTrue(torch.all(xbest <= ub))\nself.assertTrue(torch.all(xbest >= lb))\nlinear_constraints = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0]]\n    ), torch.tensor([[0.5], [1.0]])\nwith self.assertRaises(UnsupportedError):\n    Xgen, wgen = model.gen(n=n, bounds=self.bounds, objective_weights=self.\n        objective_weights, outcome_constraints=None, linear_constraints=\n        linear_constraints)\n"
}