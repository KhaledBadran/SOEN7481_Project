{
    "functionName": "test_subtract_tokens",
    "className": "TestTokenization",
    "fileName": "/dcavar_&_Py-JSON-NLP/tests_&_test_tokenization.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "a = [OrderedDict({'id': 1}), OrderedDict({'id': 2}), OrderedDict({'id': 3})]\nb = [OrderedDict({'id': 2}), OrderedDict({'id': 3}), OrderedDict({'id': 4})]\naa = list(a)\nbb = list(b)\nactual = subtract_tokens(a, b)\nexpected = [OrderedDict([('id', 1)])]\nassert expected == actual, actual\nassert a == aa\nassert b == bb\nactual = subtract_tokens(a, a)\nassert [] == actual, actual\nactual = subtract_tokens([], a)\nassert [] == actual, actual\nactual = subtract_tokens(a, [])\nassert a == actual, actual\n"
}