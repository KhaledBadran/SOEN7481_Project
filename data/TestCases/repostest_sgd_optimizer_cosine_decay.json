{
    "functionName": "test_sgd_optimizer_cosine_decay",
    "className": null,
    "fileName": "/Accenture_&_AmpliGraph/tests_&_ampligraph_&_latent_features_&_test_optimizers.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "sdg_class = OPTIMIZER_REGISTRY['sgd']\nw = tf.Variable(0.01)\nx = tf.placeholder(shape=(1,), dtype=tf.float32)\ny = tf.placeholder(shape=(1,), dtype=tf.float32)\npred = w * x\nloss = tf.losses.mean_squared_error(y, pred)\nsgd_optimizer = sdg_class({'lr': 0.001, 'end_lr': 1e-05, 'decay_lr_rate': 2,\n    'expand_factor': 2, 'cosine_decay': True, 'decay_cycle': 10}, 10)\ntrain = sgd_optimizer.minimize(loss)\nwith tf.Session() as sess:\n    for epoch in range(1, 31):\n        for batch in range(1, 11):\n            feed_dict = {}\n            sgd_optimizer.update_feed_dict(feed_dict, batch, epoch)\n            if epoch == 11 and batch == 1:\n                assert list(feed_dict.values())[0] == 0.0005\n            if epoch == 6 and batch == 1:\n                assert list(feed_dict.values())[0] == 0.000505\n            if epoch == 21 and batch == 1:\n                assert list(feed_dict.values())[0] == 0.000255\n    sgd_optimizer.update_feed_dict(feed_dict, 1, 31)\n    assert list(feed_dict.values())[0] == 0.00025\n"
}