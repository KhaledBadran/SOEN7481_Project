{
    "functionName": "test_gradient_descent_optimizer_with_averaging",
    "className": "TestOptimizer",
    "fileName": "/Yelp_&_MOE/moe_&_tests_&_optimal_learning_&_python_&_python_version_&_optimization_test.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\"Test if Gradient Descent can optimize a simple objective function.\n\n        This test doesn't exercise the purpose of averaging (i.e., this objective isn't stochastic), but it does\n        check that it at least runs.\n\n        \"\"\"\nnum_steps_averaged = self.gd_parameters.max_num_steps * 3 / 4\nparam_dict = self.gd_parameters._asdict()\nparam_dict['num_steps_averaged'] = num_steps_averaged\ngd_parameters_averaging = GradientDescentParameters(**param_dict)\ngradient_descent_optimizer = GradientDescentOptimizer(self.domain, self.\n    polynomial, gd_parameters_averaging)\nself.optimizer_test(gradient_descent_optimizer, tolerance=2e-10)\n"
}