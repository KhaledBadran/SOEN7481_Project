{
    "functionName": "test_check_model_parameters",
    "className": null,
    "fileName": "/viebboy_&_PyGOP/test_&_utility_&_test_misc.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "model = gop_models.HeMLGOP()\ndefault_params = model.get_default_parameters()\nparams = copy.deepcopy(default_params)\nwith pytest.raises(AssertionError, match=\n    'This model requires a read/writeable temporary directory'):\n    misc.check_model_parameters(params, default_params)\nparams['tmp_dir'] = tmpdir.dirname\nwith pytest.raises(AssertionError, match=\n    'This model requires a unique name in temporary directory'):\n    misc.check_model_parameters(params, default_params)\nparams['model_name'] = 'test_HeMLGOP'\nparams['tmp_dir'] = 'this is a random dir'\nwith pytest.raises(AssertionError, match='does not exist'):\n    misc.check_model_parameters(params, default_params)\nparams['tmp_dir'] = tmpdir.dirname\nwith pytest.raises(AssertionError, match='Input dimension'):\n    misc.check_model_parameters(params, default_params)\nparams['input_dim'] = utility.INPUT_DIM\nwith pytest.raises(AssertionError, match='Output dimension'):\n    misc.check_model_parameters(params, default_params)\nparams['output_dim'] = utility.OUTPUT_DIM\nassert os.path.exists(os.path.join(tmpdir.dirname, 'test_HeMLGOP'))\nparams['cluster'] = True\nwith pytest.raises(AssertionError, match='batchjob_parameters'):\n    misc.check_model_parameters(params, default_params)\ncluster_params = ['name', 'mem', 'core', 'partition', 'time', 'no_machine',\n    'python_cmd']\njob_config = {name: None for name in cluster_params}\nparams['batchjob_parameters'] = job_config\nfor name in cluster_params:\n    del params['batchjob_parameters'][name]\n    with pytest.raises(AssertionError, match=name):\n        misc.check_model_parameters(params, default_params)\n    params['batchjob_parameters'][name] = None\nparams['cluster'] = False\nparams['search_computation'] = 'cpu'\nwith pytest.raises(AssertionError, match='search_computation'):\n    misc.check_model_parameters(params, default_params)\nparams['search_computation'] = 'cpu', 'device0'\nwith pytest.raises(AssertionError, match='\"search_computation\"=\"cpu\"'):\n    misc.check_model_parameters(params, default_params)\nparams['search_computation'] = 'gpu', 0\nwith pytest.raises(AssertionError, match='\"search_computation\"=\"gpu\"'):\n    misc.check_model_parameters(params, default_params)\nparams['search_computation'] = 'cpu', 1\nparams['finetune_computation'] = 'gpu', 0\nwith pytest.raises(AssertionError, match='\"finetune_computation\"=\"gpu\"'):\n    misc.check_model_parameters(params, default_params)\nparams['finetune_computation'] = 'cpu', 1\nparams['metrics'] = utility.mean_absolute_error_keras\nwith pytest.raises(AssertionError, match=\n    'metrics should be given as a single/list/tuple'):\n    misc.check_model_parameters(params, default_params)\nparams['metrics'] = default_params['metrics']\nparams['special_metrics'] = utility.mean_absolute_error_keras\nwith pytest.raises(AssertionError, match=\n    'special_metrics should be given as a list/tuple'):\n    misc.check_model_parameters(params, default_params)\nparams['special_metrics'] = [None]\nwith pytest.raises(AssertionError, match=\n    'special_metrics should be a list/tuple of callable'):\n    misc.check_model_parameters(params, default_params)\nparams['special_metrics'] = None\nparams['convergence_measure'] = random.choice([None, 3])\nwith pytest.raises(AssertionError, match='convergence_measure'):\n    misc.check_model_parameters(params, default_params)\nparams['convergence_measure'] = 'CE'\nparams['metrics'] = ['mse', utility.mean_absolute_error_keras]\nparams['special_metrics'] = [utility.mean_absolute_error_numpy]\nwith pytest.raises(AssertionError, match='should belong to the list of metrics'\n    ):\n    misc.check_model_parameters(params, default_params)\nparams['convergence_measure'] = 'mean_absolute_error_keras'\nparams['loss'] = None\nwith pytest.raises(AssertionError, match='loss should be'):\n    misc.check_model_parameters(params, default_params)\nparams['loss'] = default_params['loss']\nparams['direction'] = 'asd'\nwith pytest.raises(AssertionError, match='direction'):\n    misc.check_model_parameters(params, default_params)\nparams['direction'] = default_params['direction']\nparams['optimizer'] = keras_optimizers.Adam()\nwith pytest.raises(AssertionError, match='Optimizer should be a str'):\n    misc.check_model_parameters(params, default_params)\nparams['optimizer'] = 'SGD'\nwith pytest.raises(AssertionError, match='Only support Keras optimizers'):\n    misc.check_model_parameters(params, default_params)\nparams['optimizer'] = 'sgd'\nparams['optimizer_parameters'] = 3\nwith pytest.raises(AssertionError, match='\"optimizer_parameters\" should be'):\n    misc.check_model_parameters(params, default_params)\n"
}