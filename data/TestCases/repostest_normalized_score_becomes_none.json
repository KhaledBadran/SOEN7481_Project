{
    "functionName": "test_normalized_score_becomes_none",
    "className": "BTBSessionTest",
    "fileName": "/HDI-Project_&_BTB/tests_&_integration_&_test_session.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "\"\"\"Tunables that worked at some point but end up removed are not tried again.\n\n        After commit ``6a08dc3cf1b68b35630cae6a87783aec4e2c9f83`` the following\n        scenario has been observed:\n\n        - One tunable produces a score at least once and then fails the next trials.\n        - All the other tunables never produce any score.\n        - Once all the tuners are created, only the one that produced a score is used.\n        - After enough errors, this one is discarded, so `_normalized_errors` is empty.\n        - Since a random.choice is used over the list of tunables, which still contains\n          the one tha has been discarded, at some point the discarded one is tried again.\n\n        This test certifies that this scenario cannot happen again, by validating that\n        the number of errors is always ``max_errors`` at most.\n        \"\"\"\nscores = []\ndef scorer(name, proposal):\n    \"\"\"Produce a score for the first trial and then fail forever.\"\"\"\n    if not scores:\n        scores.append(1)\n        return 1\n    raise Exception()\ntunables = {'a_tunable': {'a_parameter': {'type': 'int', 'default': 0,\n    'range': [0, 10]}}, 'another_tunable': {'a_parameter': {'type': 'int',\n    'default': 0, 'range': [0, 10]}}}\nsession = BTBSession(tunables, scorer, max_errors=3)\nwith pytest.raises(StopTuning):\n    session.run(8)\nassert session.errors == {'a_tunable': 3, 'another_tunable': 3}\n"
}