{
    "functionName": "standardize",
    "className": null,
    "fileName": "/Lasagne_&_Lasagne/lasagne_&_layers_&_special.py",
    "projectName": "repos",
    "Label": false,
    "isTest": false,
    "Body": "\"\"\"\n    Convenience function for standardizing inputs by applying a fixed offset\n    and scale.  This is usually useful when you want the input to your network\n    to, say, have zero mean and unit standard deviation over the feature\n    dimensions.  This layer allows you to include the appropriate statistics to\n    achieve this normalization as part of your network, and applies them to its\n    input.  The statistics are supplied as the `offset` and `scale` parameters,\n    which are applied to the input by subtracting `offset` and dividing by\n    `scale`, sharing dimensions as specified by the `shared_axes` argument.\n\n    Parameters\n    ----------\n    layer : a :class:`Layer` instance or a tuple\n        The layer feeding into this layer, or the expected input shape.\n    offset : Theano shared variable or numpy array\n        The offset to apply (via subtraction) to the axis/axes being\n        standardized.\n    scale : Theano shared variable or numpy array\n        The scale to apply (via division) to the axis/axes being standardized.\n    shared_axes : 'auto', int or tuple of int\n        The axis or axes to share the offset and scale over. If ``'auto'`` (the\n        default), share over all axes except for the second: this will share\n        scales over the minibatch dimension for dense layers, and additionally\n        over all spatial dimensions for convolutional layers.\n\n    Examples\n    --------\n    Assuming your training data exists in a 2D numpy ndarray called\n    ``training_data``, you can use this function to scale input features to the\n    [0, 1] range based on the training set statistics like so:\n\n    >>> import lasagne\n    >>> import numpy as np\n    >>> training_data = np.random.standard_normal((100, 20))\n    >>> input_shape = (None, training_data.shape[1])\n    >>> l_in = lasagne.layers.InputLayer(input_shape)\n    >>> offset = training_data.min(axis=0)\n    >>> scale = training_data.max(axis=0) - training_data.min(axis=0)\n    >>> l_std = standardize(l_in, offset, scale, shared_axes=0)\n\n    Alternatively, to z-score your inputs based on training set statistics, you\n    could set ``offset = training_data.mean(axis=0)`` and\n    ``scale = training_data.std(axis=0)`` instead.\n    \"\"\"\nlayer = BiasLayer(layer, -offset, shared_axes)\nlayer.params[layer.b].remove('trainable')\nlayer = ScaleLayer(layer, floatX(1.0) / scale, shared_axes)\nlayer.params[layer.scales].remove('trainable')\nreturn layer\n"
}