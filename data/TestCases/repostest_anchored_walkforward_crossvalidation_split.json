{
    "functionName": "test_anchored_walkforward_crossvalidation_split",
    "className": null,
    "fileName": "/Neuraxio_&_Neuraxle/testing_&_metaopt_&_test_random.py",
    "projectName": "repos",
    "Label": false,
    "isTest": true,
    "Body": "np.random.seed(10)\nbatch_size = 7\ntime_series_size = 20\nfeatures_size = 2\nvalidation_window_size_temp = validation_window_size\nif validation_window_size is None:\n    validation_window_size_temp = minimum_training_size\nif drop_remainder:\n    number_of_fold = math.floor((time_series_size - minimum_training_size -\n        padding_between_training_and_validation) / validation_window_size_temp)\nelse:\n    number_of_fold = math.ceil((time_series_size - minimum_training_size -\n        padding_between_training_and_validation) / validation_window_size_temp)\nremainder_size = (time_series_size - minimum_training_size -\n    padding_between_training_and_validation) % validation_window_size_temp\nif remainder_size == 0:\n    remainder_size = validation_window_size_temp\ndata_inputs = np.random.randint(low=0, high=1, size=(batch_size,\n    time_series_size, features_size)).astype(np.float)\nexpected_outputs = np.random.randint(low=0, high=1, size=(batch_size,\n    time_series_size, features_size)).astype(np.float)\nstep = AnchoredWalkForwardTimeSeriesCrossValidationWrapper(\n    validation_window_size=validation_window_size, minimum_training_size=\n    minimum_training_size, padding_between_training_and_validation=\n    padding_between_training_and_validation, drop_remainder=drop_remainder)\n(train_data_inputs, train_expected_outputs, validation_data_inputs,\n    validation_expected_outputs) = step.split(data_inputs, expected_outputs)\nassert len(train_data_inputs) == number_of_fold\nassert len(train_expected_outputs) == number_of_fold\nassert len(validation_data_inputs) == number_of_fold\nassert len(validation_expected_outputs) == number_of_fold\nassert train_data_inputs[0].shape == (batch_size, minimum_training_size,\n    features_size)\nassert train_expected_outputs[0].shape == (batch_size,\n    minimum_training_size, features_size)\nassert validation_data_inputs[0].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert validation_expected_outputs[0].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert train_data_inputs[1].shape == (batch_size, minimum_training_size +\n    validation_window_size_temp, features_size)\nassert train_expected_outputs[1].shape == (batch_size, \n    minimum_training_size + validation_window_size_temp, features_size)\nassert validation_data_inputs[1].shape == (batch_size,\n    validation_window_size_temp, features_size)\nassert validation_expected_outputs[1].shape == (batch_size,\n    validation_window_size_temp, features_size)\nif drop_remainder:\n    assert train_data_inputs[-1].shape == (batch_size, \n        minimum_training_size + (number_of_fold - 1) *\n        validation_window_size_temp, features_size)\n    assert train_expected_outputs[-1].shape == (batch_size, \n        minimum_training_size + (number_of_fold - 1) *\n        validation_window_size_temp, features_size)\n    assert validation_data_inputs[-1].shape == (batch_size,\n        validation_window_size_temp, features_size)\n    assert validation_expected_outputs[-1].shape == (batch_size,\n        validation_window_size_temp, features_size)\nelse:\n    assert train_data_inputs[-1].shape == (batch_size, time_series_size -\n        remainder_size - padding_between_training_and_validation, features_size\n        )\n    assert train_expected_outputs[-1].shape == (batch_size, \n        time_series_size - remainder_size -\n        padding_between_training_and_validation, features_size)\n    assert validation_data_inputs[-1].shape == (batch_size, remainder_size,\n        features_size)\n    assert validation_expected_outputs[-1].shape == (batch_size,\n        remainder_size, features_size)\npytest.mark.parametrize(\n    'minimum_training_size, validation_window_size, padding_between_training_and_validation, drop_remainder'\n    , anchored_walforward_parameters)"
}